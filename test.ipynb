{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pipeline.configs.config import DATA_PATH_TEST, PIPELINE_NAME, LOCAL_RUNNER_PATH, PIPELINE_ROOT_PATH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx pipeline create --engine=local --pipeline_path={LOCAL_RUNNER_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx run create --engine=local --pipeline_name={PIPELINE_NAME}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVING_MODEL_DIR = os.path.join(PIPELINE_ROOT_PATH, 'serving_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'http://storage.googleapis.com/tensorflow-serving-apt/pool/tensorflow-model-server-universal-2.8.0/t/tensorflow-model-server-universal/tensorflow-model-server-universal_2.8.0_all.deb'\n",
    "!sudo dpkg -i --force-overwrite tensorflow-model-server-universal_2.8.0_all.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg \n",
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=test_model \\\n",
    "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH_TEST)\n",
    "\n",
    "json_data = data.to_json(orient='records')\n",
    "\n",
    "url = 'http://localhost:8501/v1/models/{PIPELINE_NAME}:predict'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json_data, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    predictions = response.json()\n",
    "    print(predictions)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
